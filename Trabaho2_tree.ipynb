{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "CMJip5uzoL3f"
      },
      "id": "CMJip5uzoL3f",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construção de Árvore do Zero\n",
        "\n",
        "O MSE será usado como métrica de erro considerando que este é multiplicado por meio para facilitar o calculo do gradiente e da hesiana.\n",
        "\n"
      ],
      "metadata": {
        "id": "VnmGW5lYAcBV"
      },
      "id": "VnmGW5lYAcBV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f4c6a3",
      "metadata": {
        "id": "e9f4c6a3"
      },
      "outputs": [],
      "source": [
        "class TreeRegressor:\n",
        "  def __init__(self, learning_rate=0.1, max_depth=3):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_depth = max\n",
        "\n",
        "\n",
        "  def _criar_split(self, X, y, y_pred, lambda, max_inter, num_bins):\n",
        "\n",
        "    #Calculo do Gradiente e Hessiana\n",
        "    erro = y_pred - y\n",
        "    gradiente = erro\n",
        "    hessiana = np.ones(len(y))\n",
        "\n",
        "    #Regressão Logistica para Warm-Start\n",
        "    y_logreg = np.sign(gradiente)\n",
        "    w = np.abs(gradiente)\n",
        "\n",
        "    logreg = LogisticRegression(penalty='elasticnet',\n",
        "                                C=1.0/lambda,\n",
        "                                l1_ratio=lambda,\n",
        "                                solver='saga',\n",
        "                                class_weight='balanced')\n",
        "    logreg.fit(X, y_logreg, sample_weight=w)\n",
        "\n",
        "    weights = logreg.coef_[0]\n",
        "    bias = logreg.intercept_[0]\n",
        "\n",
        "    #Otimização do Hiperplano\n",
        "    best_gain = -np.inf\n",
        "    best_w, best_b = weights, bias\n",
        "    for inter in range(max_inter)\n",
        "      z = X @ weights + bias\n",
        "\n",
        "      #Constroi o histograma\n",
        "      z_min, z_max = np.min(z), np.max(z)\n",
        "      bins = np.linspace(z_min, z_max, num_bins + 1)\n",
        "\n",
        "      bin_indice = np.digitize(z, bins=bins)\n",
        "\n",
        "      hist_g = np.zeros(num_bins)\n",
        "      hist_h = np.zeros(num_bins)\n",
        "\n",
        "      for i, bin_idx in enumerate(bin_indice):\n",
        "        hist_g[bin_idx] += gradiente[i]\n",
        "        hist_h[bin_idx] += hessiana[i]\n",
        "\n",
        "      #Encontrar o Threshold\n",
        "      g_total = np.sum(hist_g)\n",
        "      h_total = np.sum(hist_h)\n",
        "\n",
        "      ganho_th = -np.inf\n",
        "      best_idx = -1\n",
        "\n",
        "      g_left, h_left = 0.0, 0.0\n",
        "      for i in range(num_bins - 1): #desconsidera o último\n",
        "        g_left += hist_g[i]\n",
        "        h_left += hist_h[i]\n",
        "\n",
        "        g_right = g_total - g_left\n",
        "        h_total = h_total - h_left\n",
        "\n",
        "\n",
        "\n",
        "      if h_total == 0:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _calcular_hist(self, X, num_bins = 256):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return gradiente, hessiana\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeRegressor:\n",
        "  def __init__(self, learning_rate=0.1, max_depth=3):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_depth = max\n",
        "\n",
        "\n",
        "  def _determinar_theta(self, X, y, w, max_z):\n",
        "    melhor_ganho = -np.inf\n",
        "    melhor_theta = None\n",
        "\n",
        "    z = X @ w\n",
        "    z = np.unique(z)\n",
        "    if (max_z != None) and (len(z) > max_z):\n",
        "      z = np.linspace(np.min(z), np.max(z), max_z)\n",
        "\n",
        "    for theta in z:\n",
        "      mascara_esquerda = z <= theta\n",
        "\n",
        "      ganho = self._calcular_ganho(y, mascara_esquerda)\n",
        "\n",
        "      if ganho > melhor_ganho:\n",
        "        melhor_ganho = ganho\n",
        "        melhor_theta = theta\n",
        "\n",
        "    return melhor_ganho, melhor_theta\n",
        "\n",
        "  def _calcular_ganho(self, y, mascara_esquerda):\n",
        "    y_esquerda = y[mascara_esquerda]\n",
        "    y_direita = y[~mascara_esquerda]\n",
        "\n",
        "    variancia_esquerda = (len(y_esquerda)/len(y)) * np.var(y_esquerda)\n",
        "    variancia_direita = (len(y_direita)/len(y)) * np.var(y_direita)\n",
        "\n",
        "    return np.var(y) - (variancia_esquerda + variancia_direita)\n"
      ],
      "metadata": {
        "id": "4sc9IagI6rl9"
      },
      "id": "4sc9IagI6rl9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}