{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "e1e5dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import random\n",
    "from sklearn.linear_model import ridge_regression\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import bisect\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "87d86264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos-monteiro/anaconda3/lib/python3.13/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>availability</th>\n",
       "      <th>size</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3452.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.584376</td>\n",
       "      <td>400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>488.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       availability  size  total_sqft  bath   balcony   price\n",
       "0                 0   2.0      1056.0   2.0  1.000000   39.07\n",
       "1                 1   4.0      2600.0   5.0  3.000000  120.00\n",
       "2                 1   3.0      1440.0   2.0  3.000000   62.00\n",
       "3                 1   3.0      1521.0   3.0  1.000000   95.00\n",
       "4                 1   2.0      1200.0   2.0  1.000000   51.00\n",
       "...             ...   ...         ...   ...       ...     ...\n",
       "13315             1   5.0      3452.0   4.0  0.000000  231.00\n",
       "13316             1   4.0      3600.0   5.0  1.584376  400.00\n",
       "13317             1   2.0      1141.0   2.0  1.000000   60.00\n",
       "13318             0   4.0      4688.0   4.0  1.000000  488.00\n",
       "13319             1   1.0       550.0   1.0  1.000000   17.00\n",
       "\n",
       "[13320 rows x 6 columns]"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "\n",
    "df.drop(['area_type', 'society', 'location'], axis=1, inplace=True)\n",
    "df['availability'] = [1 if x.strip() == ('Ready To Move' or 'Immediate Possession')\n",
    "                       else 0 for x in df['availability']]\n",
    "df['size'] = df['size'].str.extract(r'(\\d+)').astype('float16')\n",
    "df['size'] = df['size'].fillna(df['size'].mean())\n",
    "df['total_sqft'] = df['total_sqft'].str.extract(r'(\\d+)').astype('float16')\n",
    "df['bath'] = df['bath'].fillna(df['bath'].mean())\n",
    "df['balcony'] = df['balcony'].fillna(df['balcony'].mean())\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "0315fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_amostras = 5000\n",
    "\n",
    "\n",
    "dados = pd.DataFrame()\n",
    "dados['x1'] = 6 + tc.randn(num_amostras)\n",
    "dados['x2'] = [1.5*np.sin(0.002*idx) + n for idx, n in enumerate(dados['x1'])]\n",
    "dados['x3'] = [0.001*idx+n for idx, n in enumerate(dados['x1'])]\n",
    "dados['x4'] = [abs(n*np.sin(0.0025*idx))  for idx, n in enumerate(dados['x1'])]\n",
    "dados['x5'] = [n + float(tc.randn(1)) for idx, n in enumerate(dados['x1'])]\n",
    "dados['x6'] = [0.0003*idx + 0.8*np.sin(0.0008*idx) + n + float(tc.randn(1)) for idx, n in enumerate(dados['x1'])]\n",
    "dados['x7'] = tc.rand(num_amostras)\n",
    "dados['x8'] = [-np.log(n) for idx, n in enumerate(dados['x7'])]\n",
    "#dados['y'] = [10 + n*np.sin(0.0025*idx) + dados['x7'][idx]*np.sin(0.001*idx) + float(tc.randn(1)) for idx, n in enumerate(dados['x1'])]\n",
    "dados['price'] = [n + dados['x2'][idx] + dados['x3'][idx] + dados['x4'][idx] + dados['x5'][idx] + dados['x6'][idx] + dados['x7'][idx] + dados['x8'][idx] for idx, n in enumerate(dados['x1'])]\n",
    "\n",
    "df = dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "53c72318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['price']), df['price'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "f54b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    count=0\n",
    "    def __init__(self, left, right, data=None, w=None, \n",
    "                 b=None, criterion_value=None, _result=None):\n",
    "        self.id=Node.count\n",
    "        Node.count += 1\n",
    "    \n",
    "        self.left: Node = left\n",
    "        self.right: Node = right\n",
    "\n",
    "        self.data = data\n",
    "        self.w: int = w\n",
    "        self.b: float = b\n",
    "        self.criterion_value: float = criterion_value\n",
    "        self.n_sample: int = len(data) if data is not None else 0\n",
    "        self._result = _result\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = x @ self.w - self.b\n",
    "        if z < 0:\n",
    "            return self.left.predict(x)\n",
    "        \n",
    "        elif z >= 0:\n",
    "            return self.right.predict(x)\n",
    "\n",
    "class LeafNode(Node):\n",
    "    def __init__(self, data, criterion_value, _result):\n",
    "        super().__init__(None, None, data=data, \n",
    "                         criterion_value=criterion_value, \n",
    "                         _result=_result)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self._result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "a1ac594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_to_split=4, min_samples_leaf=2,\n",
    "                 n_feature_split=2, n_feature_comb_split=10, min_cost_decrease=0.1,\n",
    "                 prob_oblique_split=0.7, hist=True):\n",
    "        self.root: Node = Node(None, None)\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_to_split = min_samples_to_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.n_feature_split = n_feature_split\n",
    "        self.n_feature_comb_split = n_feature_comb_split\n",
    "        self.min_cost_decrease = min_cost_decrease\n",
    "        self.prob_oblique_split = prob_oblique_split\n",
    "        self.hist = hist\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.n_sample, self.n_feature = X.shape\n",
    "\n",
    "        if self.hist:\n",
    "            #Converte y em bins usando a regra de Freedman-Diaconis\n",
    "            bins = int((np.max(y) - np.min(y)) / (2 * (np.percentile(y, 75) - np.percentile(y, 25)) * len(y)**(-1/3)))\n",
    "            edge = np.linspace(np.min(y), np.max(y), bins)\n",
    "            y_bins = []\n",
    "            for yi in y:\n",
    "                bin = bisect.bisect_left(edge, yi)\n",
    "                y_bins.append(edge[bin-1] + (edge[bin] - edge[bin-1]) / 2)\n",
    "            y = y_bins       \n",
    "\n",
    "        #Gera todas as combinações de features\n",
    "        if self.n_feature > self.n_feature_split:\n",
    "            self.feature_combination = list(combinations(np.arange(self.n_feature), self.n_feature_split))\n",
    "        else:\n",
    "            self.feature_combination = [np.arange(self.n_feature + 1)]\n",
    "\n",
    "        self.root = self._grow(np.hstack((X.to_numpy(), np.array(y).reshape(-1,1))))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X.to_numpy():\n",
    "            y_pred.append(self.root.predict(x))\n",
    "        return y_pred\n",
    "\n",
    "   \n",
    "    def _split(self, feature_data, labels):\n",
    "    \n",
    "        #Binariza as labels\n",
    "        if len(np.unique(labels)) == 2:\n",
    "            binary_labels = labels\n",
    "        else: \n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            most_frequent_class = unique[np.argmax(counts)]\n",
    "            binary_labels = (labels == most_frequent_class).astype(int)\n",
    "\n",
    "        binary_labels = (labels >= np.median(labels)).astype(int)\n",
    "\n",
    "        if feature_data.ndim != 1:\n",
    "\n",
    "            #Aplica regressão ridge para encontrar o hiperplano de separação\n",
    "            if (Counter(binary_labels)[0] > self.min_samples_leaf and \n",
    "                Counter(binary_labels)[1] > self.min_samples_leaf):\n",
    "                w = ridge_regression(feature_data, binary_labels, alpha=0.9)\n",
    "            else:\n",
    "                return None, None, np.inf\n",
    "            \n",
    "            #Soft Theresholding\n",
    "            th = 0.1*np.max(np.abs(w))\n",
    "            for i, weight in enumerate(w):\n",
    "                if weight > th:\n",
    "                    w[i] = weight - th\n",
    "                elif weight < -th:\n",
    "                    w[i] = weight + th\n",
    "                else:\n",
    "                    w[i] = 0.0\n",
    "\n",
    "            #Define o b\n",
    "            z = feature_data @ w\n",
    "           \n",
    "        else:\n",
    "            w = np.array([1.0])\n",
    "            z = feature_data\n",
    "\n",
    "        \n",
    "\n",
    "        sorted_z_idx = np.argsort(z)\n",
    "        sorted_z = z[sorted_z_idx]\n",
    "        sorted_y = labels[sorted_z_idx]\n",
    "\n",
    "        best_b = None\n",
    "        best_cost = np.inf\n",
    "\n",
    "        for i in range(1, len(sorted_y)):\n",
    "            if sorted_z[i] != sorted_z[i-1]:\n",
    "                b_candidate = (sorted_z[i] + sorted_z[i-1]) / 2.0\n",
    "\n",
    "                left_labels = labels[z > b_candidate]\n",
    "                right_labels = labels[z <= b_candidate]\n",
    "\n",
    "                m_left, m_right = len(left_labels), len(right_labels)\n",
    "                m = m_left + m_right\n",
    "\n",
    "                s_left = np.sum((left_labels - np.mean(left_labels))**2)/m_left\n",
    "                s_right = np.sum((right_labels - np.mean(right_labels))**2)/m_right\n",
    "\n",
    "                cost_value = s_left*(m_left/m) + s_right*(m_right/m)\n",
    "\n",
    "                if cost_value < best_cost:\n",
    "                    best_cost = cost_value\n",
    "                    best_b = b_candidate\n",
    "        \n",
    "       \n",
    "        return w, best_b, best_cost\n",
    "    \n",
    "    \n",
    "    def _best_feature(self, data):\n",
    "\n",
    "        min_feature_cost = np.inf\n",
    "        min_w = None\n",
    "        min_b = None\n",
    "        selected_feature = []\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if random.uniform(0, 1) > self.prob_oblique_split:\n",
    "            sampled_feature_list = random.sample(self.feature_combination, \n",
    "                                             self.n_feature_comb_split)\n",
    "        else:\n",
    "            sampled_feature_list = np.arange(self.n_feature)\n",
    "\n",
    "        for feature_idxs in sampled_feature_list:\n",
    "\n",
    "            w, b, split_cost = self._split(data[:, feature_idxs], data[:, -1])\n",
    "\n",
    "            if split_cost < min_feature_cost:\n",
    "                min_feature_cost = split_cost\n",
    "                min_w = w\n",
    "                min_b = b\n",
    "                selected_feature = feature_idxs\n",
    "\n",
    "        if min_feature_cost != np.inf:\n",
    "            w_out = np.zeros(self.n_feature)\n",
    "            if isinstance(selected_feature, tuple):\n",
    "                for idx, f_idx in enumerate(selected_feature):\n",
    "                    w_out[f_idx] = min_w[idx]\n",
    "            else:\n",
    "                w_out[selected_feature] = 1\n",
    "        else:\n",
    "            w_out = None\n",
    "\n",
    "\n",
    "        return w_out, min_b, min_feature_cost\n",
    "        \n",
    "\n",
    "    def _grow(self, data, depth=1):\n",
    "\n",
    "        y = data[:, -1]\n",
    "\n",
    "        criterion_value = np.sum((y - np.mean(y))**2)\n",
    "        result = np.mean(y)\n",
    "\n",
    "        if ((depth >= self.max_depth) or\n",
    "            (criterion_value < np.finfo('float32').eps)):\n",
    "            return LeafNode(data, criterion_value=criterion_value, \n",
    "                            _result = result)\n",
    "       \n",
    "        w_out, min_b, min_feature_cost = self._best_feature(data)\n",
    "\n",
    "        if min_feature_cost == np.inf:\n",
    "            return LeafNode(data, criterion_value=criterion_value, \n",
    "                            _result=result)\n",
    "        \n",
    "        z = np.dot(data[:, :-1], w_out) - min_b\n",
    "    \n",
    "        left_data = data[z < 0]\n",
    "        right_data = data[z >= 0]\n",
    "\n",
    "        if ((len(left_data) < self.min_samples_leaf) or\n",
    "            (len(right_data) < self.min_samples_leaf) or\n",
    "            ((criterion_value/len(y)) - min_feature_cost <= self.min_cost_decrease)):           \n",
    "            return LeafNode(data, criterion_value=criterion_value, \n",
    "                            _result=result)\n",
    "        \n",
    "        if len(left_data) < self.min_samples_to_split:\n",
    "            left_y = left_data[:, -1]\n",
    "\n",
    "            left_criterion_value = np.sum((left_y - np.mean(left_y))**2)\n",
    "            left_result = np.mean(left_y)\n",
    "\n",
    "            left_node = LeafNode(left_data, criterion_value=left_criterion_value, \n",
    "                                 _result = left_result)\n",
    "        else:\n",
    "            left_node = self._grow(left_data, depth=depth+1)\n",
    "\n",
    "\n",
    "        if len(right_data) < self.min_samples_to_split:\n",
    "            right_y = right_data[:, -1]\n",
    "\n",
    "            right_criterion_value = np.sum((right_y - np.mean(right_y))**2)\n",
    "            right_result = np.mean(right_y)\n",
    "\n",
    "            right_node = LeafNode(right_data, criterion_value=right_criterion_value, \n",
    "                                 _result = right_result)\n",
    "        else:\n",
    "            right_node = self._grow(right_data, depth=depth+1)\n",
    "\n",
    "        return Node(left_node, \n",
    "                    right_node,\n",
    "                    data, \n",
    "                    w_out, \n",
    "                    min_b, \n",
    "                    criterion_value = criterion_value,\n",
    "                    _result=result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "9b3c7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTree(max_depth=100, min_samples_to_split=10, min_samples_leaf=3, \n",
    "                        n_feature_split=2, n_feature_comb_split=10, min_cost_decrease=0.1,\n",
    "                        prob_oblique_split=0.7, hist=True)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "83402074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node=None, dot=None):\n",
    "    if dot is None:\n",
    "        dot = Digraph()\n",
    "        dot.attr('graph', fontsize='80')\n",
    "        dot.attr('node', fontsize='80')\n",
    "    if node.left != None:\n",
    "        dot.node(f'{node.id}', f'{node.w}\\n{node.criterion_value}')\n",
    "        print_tree(node.left, dot=dot)\n",
    "        print_tree(node.right, dot=dot)\n",
    "        dot.edge(f'{node.id}', f'{node.left.id}', constraint='true')\n",
    "        dot.edge(f'{node.id}', f'{node.right.id}', constraint='true')\n",
    "    else:\n",
    "        dot.node(f'{node.id}', f'{node._result}\\n{node.criterion_value}\\n{node.n_sample}')\n",
    "    \n",
    "\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "9642f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowchart.pdf'"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = print_tree(model_dt.root)\n",
    "d.render('flowchart', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "f48dcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_sklearn = RandomForestRegressor()\n",
    "model_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = model_sklearn.predict(X_test)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "mae_sklearn = mean_absolute_error(y_test, y_pred_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "68a7dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_sklearn_dt = DecisionTreeRegressor()\n",
    "model_sklearn_dt.fit(X_train, y_train)\n",
    "y_pred_sklearn_dt = model_sklearn_dt.predict(X_test)\n",
    "mse_sklearn_dt = mean_squared_error(y_test, y_pred_sklearn_dt)\n",
    "mae_sklearn_dt = mean_absolute_error(y_test, y_pred_sklearn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "3d724b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo                |     MSE    |   MAE   \n",
      "----------------------|------------|----------\n",
      "Decision Tree         |     2.4015 |   1.1907 \n",
      "Sklearn Decision Tree |     2.5552 |   1.2373 \n",
      "Random Forest\n",
      "Sklearn Random Forest |     0.9505 |   0.7040 \n"
     ]
    }
   ],
   "source": [
    "print(f'Modelo                |     MSE    |   MAE   ')\n",
    "print(f'----------------------|------------|----------')\n",
    "print(f'Decision Tree         | {mse_dt:10.4f} | {mae_dt:8.4f} ')\n",
    "print(f'Sklearn Decision Tree | {mse_sklearn_dt:10.4f} | {mae_sklearn_dt:8.4f} ')\n",
    "print(f'Random Forest')\n",
    "print(f'Sklearn Random Forest | {mse_sklearn:10.4f} | {mae_sklearn:8.4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "4efabebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Node object at 0x7875f88d25d0> - <__main__.Node object at 0x7874c8d456d0>\n"
     ]
    }
   ],
   "source": [
    "print(f'{model_dt.root.left} - {model_dt.root.right}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
